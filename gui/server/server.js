import express from 'express';
import cors from 'cors';
import path from 'path';
import fs from 'fs';
import os from 'os';
import { fileURLToPath } from 'url';
import simpleGit from 'simple-git';
import archiver from 'archiver';
import OSS from 'ali-oss';
import less from 'less'; // ğŸš¨ æ–°å¢ Less åº“å¯¼å…¥

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const PORT = process.env.PORT || 5178;

app.use(cors());
app.use(express.json());

// æä¾›é™æ€æ–‡ä»¶æœåŠ¡ - ä»ä¸Šçº§guiç›®å½•æä¾›HTMLæ–‡ä»¶
app.use(express.static(path.join(__dirname, '..')));

// Config: projects.json mapping or directory scan
const CONFIG_PATH = path.join(__dirname, 'projects.json');
const CHANNEL_CONFIG_PATH = path.join(__dirname, 'channel-config.json');
const PROJECT_BUCKETS_PATH = path.join(__dirname, 'project-buckets.json');
const OSS_CONFIG_PATH = path.join(__dirname, 'oss-connection-config.json');
const DEFAULT_DIR = process.env.PROJECTS_DIR || '/Users/maiyou001/Project';

// Less ç¼–è¯‘ç›¸å…³å¸¸é‡
const LESS_INPUT_PATH = 'src/css/css.less';
const CSS_OUTPUT_PATH = 'src/css/css.css';

// ä»æ–°çš„é…ç½®ç»“æ„ä¸­è·å– bucket é…ç½®
function getBucketConfig(ossConfigs, projectName, channelId = null, env = 'dev') {
  try {
    console.log(`getBucketConfig called: projectName=${projectName}, channelId=${channelId}, env=${env}`);
    
    const projectConfig = ossConfigs.projects?.[projectName];
    if (!projectConfig) {
      console.log(`Project ${projectName} not found in config`);
      return null;
    }
    
    console.log(`Found project config:`, projectConfig.name);
    
    // å¤šæ¸ é“é¡¹ç›®
    if (projectConfig.channels && channelId) {
      console.log(`Processing multi-channel project with channelId: ${channelId}`);
      
      const channelConfig = projectConfig.channels[channelId];
      if (!channelConfig) {
        console.log(`Channel ${channelId} not found in project ${projectName}`);
        return null;
      }
      
      console.log(`Found channel config:`, channelConfig.name);
      
      const bucketInfo = channelConfig.buckets?.[env];
      if (!bucketInfo) {
        console.log(`Bucket info not found for env ${env} in channel ${channelId}`);
        return null;
      }
      
      console.log(`Found bucket info:`, bucketInfo);
      
      // å¤„ç†ä¸åŒæ ¼å¼
      if (typeof bucketInfo === 'string') {
        return {
          name: bucketInfo,
          region: ossConfigs.connection.region,
          prefix: '',
          url: `https://${bucketInfo}.oss-cn-hangzhou.aliyuncs.com`,
          enabled: true
        };
      } else if (Array.isArray(bucketInfo)) {
        return bucketInfo;
      } else {
        return {
          name: bucketInfo.name,
          region: bucketInfo.region,
          prefix: bucketInfo.prefix || '',
          url: bucketInfo.url,
          enabled: bucketInfo.enabled !== false
        };
      }
    }
    
    // å•æ¸ é“é¡¹ç›®
    if (projectConfig.buckets) {
      const bucketInfo = projectConfig.buckets[env];
      if (!bucketInfo) return null;
      
      // å¤„ç†æ•°ç»„ï¼ˆå¤šä¸ªç”Ÿäº§ç¯å¢ƒï¼‰
      if (Array.isArray(bucketInfo)) {
        return bucketInfo;
      } else if (typeof bucketInfo === 'string') {
        return {
          name: bucketInfo,
          region: ossConfigs.connection.region,
          prefix: '',
          url: `https://${bucketInfo}.oss-cn-hangzhou.aliyuncs.com`
        };
      } else {
        return {
          name: bucketInfo.name,
          region: bucketInfo.region,
          prefix: bucketInfo.prefix || '',
          url: bucketInfo.url
        };
      }
    }
    
    return null;
  } catch (e) {
    console.error('Error getting bucket config:', e);
    return null;
  }
}


function readConfig() {
  try {
    if (fs.existsSync(CONFIG_PATH)) {
      const raw = fs.readFileSync(CONFIG_PATH, 'utf-8');
      const data = JSON.parse(raw);
      const toAbs = (p) => p.replace(/^~(?=\/|$)/, os.homedir());
      if (Array.isArray(data)) return data.map(x => ({ ...x, path: toAbs(x.path) })); // [{name, path}]
      if (Array.isArray(data.projects)) return data.projects.map(x => ({ ...x, path: toAbs(x.path) }));
    }
  } catch (e) {
    console.error('Failed to read projects.json:', e.message);
  }
  return null;
}

function scanProjects(dir) {
  const entries = [];
  try {
    const names = fs.readdirSync(dir, { withFileTypes: true });
    for (const d of names) {
      if (!d.isDirectory()) continue;
      const p = path.join(dir, d.name);
      const gitDir = path.join(p, '.git');
      if (fs.existsSync(gitDir) && fs.lstatSync(gitDir).isDirectory()) {
        entries.push({ name: d.name, path: p });
      }
    }
  } catch (e) {
    // ignore
  }
  return entries;
}

async function getLastCommitTime(repoPath) {
  try {
    const git = simpleGit({ baseDir: repoPath });
    const log = await git.log({ maxCount: 1 });
    if (log && log.latest && log.latest.date) {
      return new Date(log.latest.date).toISOString();
    }
  } catch (e) {
    // ignore
  }
  // fallback: directory mtime
  try {
    const stat = fs.statSync(repoPath);
    return stat.mtime.toISOString();
  } catch (_) {
    return new Date().toISOString();
  }
}

async function getStatusCounts(repoPath) {
  try {
    const git = simpleGit({ baseDir: repoPath });
    const status = await git.status();
    const modified = (status.modified?.length || 0) + (status.renamed?.length || 0) + (status.staged?.length || 0);
    const added = (status.created?.length || 0) + (status.not_added?.length || 0);
    const deleted = (status.deleted?.length || 0);
    const isClean = status.isClean();
    return { modified, added, deleted, isClean };
  } catch (e) {
    return { modified: 0, added: 0, deleted: 0, isClean: true, error: e.message };
  }
}

async function getCurrentBranch(repoPath) {
  try {
    const git = simpleGit({ baseDir: repoPath });
    const branch = await git.branch();
    return branch.current;
  } catch (e) {
    return 'unknown';
  }
}

async function getWeeklyCommits(repoPath, days = 7) {
  try {
    const git = simpleGit({ baseDir: repoPath });
    const since = new Date();
    since.setDate(since.getDate() - days);
    const sinceStr = since.toISOString().split('T')[0];
    
    // Get commit log
    const log = await git.log({ '--since': sinceStr, '--all': true });
    const commits = log.all || [];
    
    // Get stats for each commit
    const detailedCommits = await Promise.all(
      commits.slice(0, 50).map(async (commit) => {
        try {
          const diff = await git.diffSummary([`${commit.hash}^`, commit.hash]);
          return {
            hash: commit.hash.substring(0, 7),
            message: commit.message,
            author: commit.author_name,
            email: commit.author_email,
            date: commit.date,
            insertions: diff.insertions || 0,
            deletions: diff.deletions || 0,
            files: diff.files.length
          };
        } catch (e) {
          // First commit might not have parent
          return {
            hash: commit.hash.substring(0, 7),
            message: commit.message,
            author: commit.author_name,
            email: commit.author_email,
            date: commit.date,
            insertions: 0,
            deletions: 0,
            files: 0
          };
        }
      })
    );
    
    return detailedCommits;
  } catch (e) {
    return [];
  }
}

async function getTodayCommits(repoPath) {
  try {
    const git = simpleGit({ baseDir: repoPath });
    const today = new Date();
    today.setHours(0, 0, 0, 0);
    const sinceStr = today.toISOString();
    
    const log = await git.log({ '--since': sinceStr, '--all': true });
    const commits = log.all || [];
    
    const detailedCommits = await Promise.all(
      commits.map(async (commit) => {
        try {
          const diff = await git.diffSummary([`${commit.hash}^`, commit.hash]);
          return {
            hash: commit.hash.substring(0, 7),
            message: commit.message,
            author: commit.author_name,
            email: commit.author_email,
            date: commit.date,
            insertions: diff.insertions || 0,
            deletions: diff.deletions || 0,
            files: diff.files.length,
            changedFiles: diff.files.map(f => f.file).slice(0, 5)
          };
        } catch (e) {
          return {
            hash: commit.hash.substring(0, 7),
            message: commit.message,
            author: commit.author_name,
            email: commit.author_email,
            date: commit.date,
            insertions: 0,
            deletions: 0,
            files: 0,
            changedFiles: []
          };
        }
      })
    );
    
    return detailedCommits;
  } catch (e) {
    return [];
  }
}

app.get('/api/health', (_req, res) => {
  res.json({ ok: true, port: PORT, projectsDir: DEFAULT_DIR });
});

app.get('/api/projects', async (_req, res) => {
  let projects = readConfig();
  if (!projects) {
    // å¦‚æœæ²¡æœ‰projects.jsonæ–‡ä»¶ï¼Œè¿”å›ç©ºæ•°ç»„
    projects = [];
  }

  // Enrich with lastCommitTime, status, and branch
  const enriched = await Promise.all(
    projects.map(async (p) => {
      const [lastCommitTime, status, branch] = await Promise.all([
        getLastCommitTime(p.path),
        getStatusCounts(p.path),
        getCurrentBranch(p.path)
      ]);
      return { ...p, lastCommitTime, status, branch };
    })
  );
  res.json({
    success: true,
    message: enriched,
    count: enriched.length
  });
});

// æ‰«æé¡¹ç›®ç«¯ç‚¹
app.post('/api/projects/scan', async (_req, res) => {
  try {
    // é‡æ–°æ‰«æé¡¹ç›®ç›®å½•
    const scannedProjects = scanProjects(DEFAULT_DIR);
    
    // Enrich with lastCommitTime, status, and branch
    const enriched = await Promise.all(
      scannedProjects.map(async (p) => {
        const [lastCommitTime, status, branch] = await Promise.all([
          getLastCommitTime(p.path),
          getStatusCounts(p.path),
          getCurrentBranch(p.path)
        ]);
        return { ...p, lastCommitTime, status, branch };
      })
    );
    
    res.json({ 
      success: true, 
      message: enriched,
      count: enriched.length 
    });
  } catch (error) {
    console.error('Scan projects error:', error);
    res.status(500).json({ 
      success: false, 
      error: 'æ‰«æé¡¹ç›®å¤±è´¥: ' + error.message 
    });
  }
});

app.get('/api/status', async (req, res) => {
  const repoPath = req.query.path;
  if (!repoPath) return res.status(400).json({ error: 'Missing path' });
  const counts = await getStatusCounts(repoPath);
  res.json(counts);
});

// Get weekly commits with stats
app.get('/api/commits/weekly', async (req, res) => {
  try {
    let projects = readConfig();
    if (!projects) projects = scanProjects(DEFAULT_DIR);
    
    const allCommits = [];
    for (const project of projects) {
      const commits = await getWeeklyCommits(project.path, 7);
      allCommits.push(...commits.map(c => ({ ...c, project: project.name })));
    }
    
    // Sort by date descending
    allCommits.sort((a, b) => new Date(b.date) - new Date(a.date));
    
    // Group by day for chart
    const dailyStats = {};
    const today = new Date();
    for (let i = 0; i < 7; i++) {
      const date = new Date(today);
      date.setDate(date.getDate() - i);
      const dayKey = date.toISOString().split('T')[0];
      dailyStats[dayKey] = { commits: 0, insertions: 0, deletions: 0, lines: 0 };
    }
    
    allCommits.forEach(commit => {
      const dayKey = commit.date.split('T')[0];
      if (dailyStats[dayKey]) {
        dailyStats[dayKey].commits++;
        dailyStats[dayKey].insertions += commit.insertions;
        dailyStats[dayKey].deletions += commit.deletions;
        dailyStats[dayKey].lines += (commit.insertions + commit.deletions);
      }
    });
    
    res.json({ commits: allCommits, dailyStats });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Get today's commits
app.get('/api/commits/today', async (req, res) => {
  try {
    let projects = readConfig();
    if (!projects) projects = scanProjects(DEFAULT_DIR);
    
    const allCommits = [];
    for (const project of projects) {
      const commits = await getTodayCommits(project.path);
      allCommits.push(...commits.map(c => ({ ...c, project: project.name })));
    }
    
    // Sort by date descending
    allCommits.sort((a, b) => new Date(b.date) - new Date(a.date));
    
    res.json({ commits: allCommits, count: allCommits.length });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Execute git pull
app.post('/api/git/pull', async (req, res) => {
  try {
    const { path: repoPath } = req.body || {};
    if (!repoPath) return res.status(400).json({ error: 'Missing path' });
    const git = simpleGit({ baseDir: repoPath });
    await git.fetch();
    const result = await git.pull();
    const counts = await getStatusCounts(repoPath);
    const lastCommitTime = await getLastCommitTime(repoPath);
    res.json({ ok: true, result, status: counts, lastCommitTime });
  } catch (e) {
    res.status(500).json({ ok: false, error: e.message });
  }
});

// Execute git push (with optional add/commit)
app.post('/api/git/push', async (req, res) => {
  try {
    const { path: repoPath, message } = req.body || {};
    if (!repoPath) return res.status(400).json({ error: 'Missing path' });
    const git = simpleGit({ baseDir: repoPath });
    // stage changes if any
    const status = await git.status();
    if (!status.isClean()) {
      await git.add(['.']);
      const msg = message || `chore: update from UI ${new Date().toISOString()}`;
      try {
        await git.commit(msg);
      } catch (commitErr) {
        // ignore if nothing to commit due to race
      }
    }
    const result = await git.push();
    const counts = await getStatusCounts(repoPath);
    const lastCommitTime = await getLastCommitTime(repoPath);
    res.json({ ok: true, result, status: counts, lastCommitTime });
  } catch (e) {
    res.status(500).json({ ok: false, error: e.message });
  }
});

// è·å–é¡¹ç›®çš„æ¸ é“é…ç½®
app.get('/api/channels/:projectName', (req, res) => {
  try {
    const { projectName } = req.params;
    let channels = {};
    
    // ä»channel-config.jsonè¯»å–å®Œæ•´é…ç½®ï¼ˆåŒ…å«filesè§„åˆ™ï¼‰
    if (fs.existsSync(CHANNEL_CONFIG_PATH)) {
      const channelConfig = JSON.parse(fs.readFileSync(CHANNEL_CONFIG_PATH, 'utf-8'));
      const projectConfig = channelConfig.projects[projectName];
      if (projectConfig && projectConfig.channels) {
        channels = projectConfig.channels;
      }
    }
    
    // ä»oss-connection-config.jsonè¯»å–bucketsé…ç½®å¹¶åˆå¹¶
    if (fs.existsSync(OSS_CONFIG_PATH)) {
      const ossConfig = JSON.parse(fs.readFileSync(OSS_CONFIG_PATH, 'utf-8'));
      const projectConfig = ossConfig.projects[projectName];
      
      if (projectConfig && projectConfig.channels) {
        // åˆå¹¶channelsé…ç½®
        for (const [channelId, channelData] of Object.entries(projectConfig.channels)) {
          if (channels[channelId]) {
            // åˆå¹¶bucketsé…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨oss-connection-config.jsonä¸­çš„é…ç½®
            if (channelData.buckets) {
              channels[channelId].buckets = channelData.buckets;
            }
          } else {
            // å¦‚æœchannel-config.jsonä¸­æ²¡æœ‰è¿™ä¸ªchannelï¼Œç›´æ¥ä½¿ç”¨ossé…ç½®
            channels[channelId] = channelData;
          }
        }
      }
    }
    
    res.json({ channels });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// æ£€æŸ¥ build ç›®å½•æ˜¯å¦å­˜åœ¨
app.post('/api/check-build', (req, res) => {
  try {
    const { projectName, path: projectPath } = req.body;
    
    if (!projectPath) {
      return res.status(400).json({ ok: false, error: 'Missing project path' });
    }
    
    const buildPath = path.join(projectPath, 'build');
    const exists = fs.existsSync(buildPath);
    
    let fileCount = 0;
    if (exists) {
      try {
        // ç»Ÿè®¡æ–‡ä»¶æ•°é‡ï¼ˆå¿½ç•¥ç³»ç»Ÿæ–‡ä»¶ï¼‰
        const shouldIgnoreFile = (filename) => {
          const ignoreList = ['.DS_Store', 'Thumbs.db', '.gitkeep', '.gitignore'];
          return ignoreList.includes(filename);
        };
        
        const countFiles = (dir) => {
          const entries = fs.readdirSync(dir, { withFileTypes: true });
          let count = 0;
          for (const entry of entries) {
            if (shouldIgnoreFile(entry.name)) {
              continue; // è·³è¿‡ç³»ç»Ÿæ–‡ä»¶
            }
            if (entry.isDirectory()) {
              count += countFiles(path.join(dir, entry.name));
            } else {
              count++;
            }
          }
          return count;
        };
        fileCount = countFiles(buildPath);
      } catch (e) {
        // ignore error
      }
    }
    
    res.json({ 
      ok: true,
      exists,
      buildPath,
      fileCount,
      isEmpty: exists && fileCount === 0
    });
  } catch (e) {
    res.status(500).json({ ok: false, error: e.message });
  }
});

// è·å–é¡¹ç›®çš„ bucket é…ç½®ï¼ˆéå¤šæ¸ é“é¡¹ç›®ï¼‰
app.get('/api/project-buckets/:projectName', (req, res) => {
  try {
    const { projectName } = req.params;
    if (!fs.existsSync(OSS_CONFIG_PATH)) {
      return res.status(404).json({ error: 'OSS config not found' });
    }
    
    const config = JSON.parse(fs.readFileSync(OSS_CONFIG_PATH, 'utf-8'));
    const projectConfig = config.projects[projectName];
    
    if (!projectConfig) {
      return res.json({ buckets: null });
    }
    
    res.json({ 
      name: projectConfig.name,
      buckets: projectConfig.buckets,
      description: projectConfig.description 
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

/**
 * ç¼–è¯‘ Less æ–‡ä»¶åˆ° CSS æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆ Source Map
 * @param {string} projectPath - é¡¹ç›®çš„æ ¹ç›®å½•è·¯å¾„
 * @param {string} lessFilePath - Less æ–‡ä»¶ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ï¼Œä¾‹å¦‚ 'src/css/css.less'
 * @param {string} cssOutputPath - ç›®æ ‡ CSS æ–‡ä»¶ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ï¼Œä¾‹å¦‚ 'src/css/css.css'
 */
async function compileLess(projectPath, lessFilePath, cssOutputPath) {
    const fullLessPath = path.join(projectPath, lessFilePath);
    const fullCssPath = path.join(projectPath, cssOutputPath);
    const mapOutputPath = fullCssPath + '.map'; // Source Map æ–‡ä»¶çš„è·¯å¾„

    if (!fs.existsSync(fullLessPath)) {
        console.warn(`Less file not found: ${fullLessPath}`);
        return false;
    }

    try {
        const lessContent = fs.readFileSync(fullLessPath, 'utf8');

        const output = await less.render(lessContent, {
            // é…ç½®é€‰é¡¹ï¼špaths ç”¨äºå¤„ç† @import è¯­å¥
            paths: [path.dirname(fullLessPath)],
            filename: path.basename(lessFilePath),
            
            // ğŸš¨ å…³é”®ä¿®æ”¹ç‚¹ 1: å¯ç”¨ Source Map
            sourceMap: {
                // filename å¿…é¡»æ˜¯ç›¸å¯¹äº CSS æ–‡ä»¶æœ¬èº«çš„è·¯å¾„
                outputFilename: path.basename(mapOutputPath), 
                // sourceMapURL æ˜¯ CSS æ–‡ä»¶åº•éƒ¨å¼•ç”¨çš„æ–‡ä»¶å
                sourceMapURL: path.basename(mapOutputPath)
            }
        });

        // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        fs.mkdirSync(path.dirname(fullCssPath), { recursive: true });
        
        // ğŸš¨ å…³é”®ä¿®æ”¹ç‚¹ 2: å†™å…¥æ–°çš„ CSS æ–‡ä»¶
        fs.writeFileSync(fullCssPath, output.css, 'utf8');
        console.log(`âœ… CSS file generated: ${cssOutputPath}`);

        // ğŸš¨ å…³é”®ä¿®æ”¹ç‚¹ 3: å†™å…¥ Source Map æ–‡ä»¶
        if (output.map) {
             fs.writeFileSync(mapOutputPath, output.map, 'utf8');
             console.log(`âœ… Source Map generated: ${cssOutputPath}.map`);
        } else {
             console.warn(`âš ï¸ Source Map was enabled but not generated for: ${lessFilePath}`);
        }
        
        return true;
    } catch (error) {
        console.error(`âŒ Less compilation failed for ${lessFilePath}:`, error);
        throw new Error(`Less compilation error: ${error.message}`);
    }
}

// åˆ‡æ¢é¡¹ç›®æ¸ é“é…ç½®
app.post('/api/switch-channel', async (req, res) => {
  try {
    const { projectName, channel } = req.body;
    
    if (!projectName || !channel) {
      return res.status(400).json({ error: 'Missing projectName or channel' });
    }
    
    const config = JSON.parse(fs.readFileSync(CHANNEL_CONFIG_PATH, 'utf-8'));
    const projectConfig = config.projects[projectName];
    
    if (!projectConfig || !projectConfig.channels[channel]) {
      return res.status(404).json({ error: 'Project or channel not found' });
    }
    
    const channelConfig = projectConfig.channels[channel];
    const projectPath = path.join(DEFAULT_DIR, projectName);
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ error: 'Project path not found' });
    }
    
    const results = [];
    let lessFileModified = false;
    
    // æ‰§è¡Œpre-buildè„šæœ¬
    if (channelConfig.scripts && channelConfig.scripts['pre-build']) {
      const { execSync } = await import('child_process');
      
      for (const script of channelConfig.scripts['pre-build']) {
        try {
          console.log(`Executing pre-build script: ${script}`);
          const output = execSync(script, { 
            cwd: projectPath, 
            encoding: 'utf-8',
            stdio: 'pipe'
          });
          results.push({ script, status: 'executed', output: output.trim() });
        } catch (error) {
          console.warn(`Script execution failed: ${script}`, error.message);
          results.push({ script, status: 'failed', error: error.message });
        }
      }
    }
    
    // å¤„ç†æ¯ä¸ªæ–‡ä»¶çš„è§„åˆ™
    for (const [filePath, fileConfig] of Object.entries(channelConfig.files)) {
      const fullPath = path.join(projectPath, filePath);
      
      if (!fs.existsSync(fullPath)) {
        results.push({ file: filePath, status: 'skipped', reason: 'File not found' });
        continue;
      }
      
      let content = fs.readFileSync(fullPath, 'utf-8');
      let modified = false;
      
      for (const rule of fileConfig.rules) {
        if (rule.action === 'replace') {
          // ç›´æ¥æ›¿æ¢æ•´ä¸ªæ–‡ä»¶å†…å®¹
          if (rule.content !== undefined) {
            content = rule.content;
            modified = true;
          }
          continue; // è·³è¿‡å…¶ä»–å¤„ç†
        }
        
        const regex = new RegExp(rule.pattern, 'gm');
        
        if (rule.action === 'comment') {
          // æ·»åŠ æ³¨é‡Šï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ³¨é‡Šï¼‰
          const newContent = content.replace(regex, (match, captured) => {
            // æ£€æŸ¥capturedæ˜¯å¦å·²ç»è¢«æ³¨é‡Š
            const trimmedCaptured = captured.trim();
            if (trimmedCaptured.startsWith('//') || trimmedCaptured.startsWith('<!--')) {
              return match; // å·²ç»æ˜¯æ³¨é‡Šäº†ï¼Œä¿æŒåŸæ ·
            }
            modified = true;
            // æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æ³¨é‡Šç¬¦å·
            if (fullPath.endsWith('.html')) {
              return `<!-- ${captured} -->`;
            } else {
              return `// ${captured}`;
            }
          });
          content = newContent;
        } else if (rule.action === 'uncomment') {
          // ç§»é™¤æ³¨é‡Š - å¤„ç†å¤šå±‚æ³¨é‡Šçš„æƒ…å†µ
          const newContent = content.replace(regex, (match, captured) => {
            let result = captured;
            
            // å¤„ç†å¤šå±‚æ³¨é‡Šï¼šä»å¤–å±‚å‘å†…å±‚é€å±‚ç§»é™¤æ³¨é‡Š
            if (fullPath.endsWith('.html')) {
              // å¤„ç†HTMLå¤šå±‚æ³¨é‡Š
              while (result.trim().startsWith('<!--') && result.trim().endsWith('-->')) {
                result = result.replace(/^(\s*)<!--\s*/, '$1').replace(/\s*-->\s*$/, '');
              }
            } else {
              // å¤„ç†JSå¤šå±‚æ³¨é‡Š
              while (result.trim().startsWith('//')) {
                result = result.replace(/^(\s*)\/\/\s*/, '$1');
              }
            }
            
            modified = true;
            return result;
          });
          content = newContent;
        }
      }
      
      if (modified) {
        fs.writeFileSync(fullPath, content, 'utf-8');
        results.push({ file: filePath, status: 'modified' });
        
        // æ£€æŸ¥æ˜¯å¦ä¿®æ”¹äº†Lessæ–‡ä»¶
        if (filePath === LESS_INPUT_PATH) {
          lessFileModified = true;
        }
      } else {
        results.push({ file: filePath, status: 'unchanged' });
      }
    }
    
    // æ£€æŸ¥ Less æ–‡ä»¶æ˜¯å¦éœ€è¦ç¼–è¯‘ (å¦‚æœæ¸ é“é…ç½®ä¸­æœ‰lessæ–‡ä»¶è§„åˆ™ï¼Œæ€»æ˜¯ç¼–è¯‘)
    const hasLessRules = channelConfig.files && channelConfig.files[LESS_INPUT_PATH];
    
    if (lessFileModified || hasLessRules) {
        await compileLess(projectPath, LESS_INPUT_PATH, CSS_OUTPUT_PATH);
        results.push({ file: CSS_OUTPUT_PATH, status: 'generated' });
    } else {
        results.push({ file: CSS_OUTPUT_PATH, status: 'skipped (no less rules)' });
    }
    
    // æ‰§è¡Œpost-buildè„šæœ¬
    if (channelConfig.scripts && channelConfig.scripts['post-build']) {
      const { execSync } = await import('child_process');
      
      for (const script of channelConfig.scripts['post-build']) {
        try {
          console.log(`Executing post-build script: ${script}`);
          const output = execSync(script, { 
            cwd: projectPath, 
            encoding: 'utf-8',
            stdio: 'pipe'
          });
          results.push({ script, status: 'executed', output: output.trim() });
        } catch (error) {
          console.warn(`Script execution failed: ${script}`, error.message);
          results.push({ script, status: 'failed', error: error.message });
        }
      }
    }

    res.json({ 
      ok: true, 
      channel: channelConfig.name,
      results 
    });
  } catch (e) {
    res.status(500).json({ ok: false, error: e.message });
  }
});

// æ„å»ºé¡¹ç›®ï¼ˆå¸¦æ¸ é“åˆ‡æ¢ï¼‰
app.post('/api/build-channel', async (req, res) => {
  try {
    const { projectName, channel } = req.body;
    
    if (!projectName) {
      return res.status(400).json({ error: 'Missing projectName' });
    }
    
    const projectPath = path.join(DEFAULT_DIR, projectName);
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ error: 'Project not found' });
    }
    
    // å¦‚æœæŒ‡å®šäº†æ¸ é“ï¼Œå…ˆåˆ‡æ¢é…ç½®
    if (channel) {
      const switchResponse = await fetch(`http://localhost:${PORT}/api/switch-channel`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ projectName, channel })
      });
      
      if (!switchResponse.ok) {
        return res.status(500).json({ error: 'Failed to switch channel' });
      }
    }
    
    // æ‰§è¡Œæ„å»º
    const { exec } = await import('child_process');
    const { promisify } = await import('util');
    const execAsync = promisify(exec);
    
    const { stdout, stderr } = await execAsync('npm run build', {
      cwd: projectPath,
      timeout: 300000 // 5åˆ†é’Ÿè¶…æ—¶
    });
    
    res.json({ 
      ok: true, 
      channel,
      stdout, 
      stderr,
      buildPath: path.join(projectPath, 'build')
    });
  } catch (e) {
    res.status(500).json({ ok: false, error: e.message, stderr: e.stderr });
  }
});

// æµå¼æ„å»ºï¼ˆå®æ—¶è¾“å‡ºï¼‰
app.get('/api/build-stream', async (req, res) => {
  try {
    const { projectName, channel } = req.query;
    
    if (!projectName) {
      return res.status(400).json({ error: 'Missing projectName' });
    }
    
    // ä»é…ç½®ä¸­è·å–é¡¹ç›®è·¯å¾„
    let projects = readConfig();
    if (!projects) projects = scanProjects(DEFAULT_DIR);
    
    const project = projects.find(p => p.name === projectName);
    if (!project) {
      return res.status(404).json({ error: 'Project not found in config' });
    }
    
    const projectPath = project.path;
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ error: 'Project path does not exist' });
    }
    
    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // ç¬¬ä¸€æ­¥ï¼šæ¸…ç©ºbuildæ–‡ä»¶å¤¹
    res.write(`data: ${JSON.stringify({ type: 'log', message: 'æ¸…ç©ºbuildæ–‡ä»¶å¤¹...' })}\n\n`);
    
    const buildPath = path.join(projectPath, 'build');
    if (fs.existsSync(buildPath)) {
      try {
        // é€’å½’åˆ é™¤buildç›®å½•å†…å®¹
        const { execSync } = await import('child_process');
        execSync(`rm -rf "${buildPath}"/*`, { cwd: projectPath });
        res.write(`data: ${JSON.stringify({ type: 'log', message: 'buildæ–‡ä»¶å¤¹å·²æ¸…ç©º' })}\n\n`);
      } catch (err) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: 'æ¸…ç©ºbuildæ–‡ä»¶å¤¹å¤±è´¥: ' + err.message })}\n\n`);
        res.end();
        return;
      }
    } else {
      res.write(`data: ${JSON.stringify({ type: 'log', message: 'buildæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç©ºæ­¥éª¤' })}\n\n`);
    }
    
    // ç¬¬äºŒæ­¥ï¼šå¦‚æœæ˜¯å¤šæ¸ é“é¡¹ç›®ï¼Œåˆ‡æ¢æ¸ é“é…ç½®
    if (channel) {
      res.write(`data: ${JSON.stringify({ type: 'log', message: `åˆ‡æ¢åˆ°æ¸ é“: ${channel}` })}\n\n`);
      
      try {
        const switchResponse = await fetch(`http://localhost:${PORT}/api/switch-channel`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ projectName, channel })
        });
        
        if (!switchResponse.ok) {
          const errorData = await switchResponse.text();
          res.write(`data: ${JSON.stringify({ type: 'error', message: 'Failed to switch channel: ' + errorData })}\n\n`);
          res.end();
          return;
        }
        res.write(`data: ${JSON.stringify({ type: 'log', message: 'æ¸ é“åˆ‡æ¢å®Œæˆ' })}\n\n`);
      } catch (err) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: err.message })}\n\n`);
        res.end();
        return;
      }
    }
    
    // ä½¿ç”¨ spawn æ‰§è¡Œæ„å»ºï¼Œå®æ—¶è·å–è¾“å‡º
    const { spawn } = await import('child_process');
    
    res.write(`data: ${JSON.stringify({ type: 'log', message: 'å¼€å§‹æ„å»º...' })}\n\n`);
    
    const buildProcess = spawn('npm', ['run', 'build'], {
      cwd: projectPath,
      shell: true
    });
    
    buildProcess.stdout.on('data', (data) => {
      const lines = data.toString().split('\n').filter(line => line.trim());
      lines.forEach(line => {
        res.write(`data: ${JSON.stringify({ type: 'stdout', message: line })}\n\n`);
      });
    });
    
    buildProcess.stderr.on('data', (data) => {
      const lines = data.toString().split('\n').filter(line => line.trim());
      lines.forEach(line => {
        res.write(`data: ${JSON.stringify({ type: 'stderr', message: line })}\n\n`);
      });
    });
    
    buildProcess.on('close', (code) => {
      if (code === 0) {
        res.write(`data: ${JSON.stringify({ type: 'success', message: 'æ„å»ºæˆåŠŸ', buildPath: path.join(projectPath, 'build') })}\n\n`);
      } else {
        res.write(`data: ${JSON.stringify({ type: 'error', message: `æ„å»ºå¤±è´¥ï¼Œé€€å‡ºç : ${code}` })}\n\n`);
      }
      res.end();
    });
    
    buildProcess.on('error', (err) => {
      res.write(`data: ${JSON.stringify({ type: 'error', message: err.message })}\n\n`);
      res.end();
    });
    
  } catch (e) {
    res.write(`data: ${JSON.stringify({ type: 'error', message: e.message })}\n\n`);
    res.end();
  }
});

// æµå¼ä¸Šä¼ åˆ° OSSï¼ˆå®æ—¶è¿›åº¦ï¼‰
app.get('/api/upload-stream', async (req, res) => {
  try {
    const { projectName, path: projectPath, channelId, env } = req.query;
    
    if (!projectName || !channelId || !env) {
      return res.status(400).json({ ok: false, error: 'Missing required parameters' });
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ ok: false, error: 'Project not found' });
    }
    
    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // è¯»å– OSS è¿æ¥é…ç½®
    if (!fs.existsSync(OSS_CONFIG_PATH)) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'OSS connection config not found' })}\n\n`);
      res.end();
      return;
    }
    
    let ossConfig, allBuckets;
    try {
      const ossData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
      const ossConfigs = JSON.parse(ossData);
      ossConfig = ossConfigs.connection;
      
      // è·å–æ‰€æœ‰å¯ç”¨ buckets
      const bucketConfig = getBucketConfig(ossConfigs, projectName, channelId, env);
      allBuckets = Array.isArray(bucketConfig) ? bucketConfig : [bucketConfig];
      
      if (!allBuckets || allBuckets.length === 0) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: 'No buckets configured' })}\n\n`);
        res.end();
        return;
      }
    } catch (e) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: e.message })}\n\n`);
      res.end();
      return;
    }
    
    // æ£€æŸ¥æ„å»ºç›®å½•
    const buildPath = path.join(projectPath, 'build');
    if (!fs.existsSync(buildPath)) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'Build directory not found. Please build first.' })}\n\n`);
      res.end();
      return;
    }
    
    // åŠ¨æ€å¯¼å…¥ ali-oss
    const OSS = (await import('ali-oss')).default;
    
    const allResults = [];
    let totalFiles = 0;
    let globalUploadedFiles = 0;
    
    // å…ˆè®¡ç®—æ€»æ–‡ä»¶æ•°
    const countFiles = (dirPath) => {
      let count = 0;
      const entries = fs.readdirSync(dirPath, { withFileTypes: true });
      for (const entry of entries) {
        const fullPath = path.join(dirPath, entry.name);
        if (entry.isDirectory()) {
          count += countFiles(fullPath);
        } else {
          count++;
        }
      }
      return count;
    };
    
    totalFiles = countFiles(buildPath);
    res.write(`data: ${JSON.stringify({ type: 'start', total: totalFiles, message: 'å¼€å§‹ä¸Šä¼ æ–‡ä»¶...' })}\n\n`);
    
    // ä¸Šä¼ åˆ°æ¯ä¸ª bucket
    for (let bucketIndex = 0; bucketIndex < allBuckets.length; bucketIndex++) {
      const bucket = allBuckets[bucketIndex];
      if (bucket.enabled === false) continue;
      
      // ä¸ºæ¯ä¸ªbucketå‘é€å¼€å§‹æ¶ˆæ¯
      res.write(`data: ${JSON.stringify({ type: 'bucket_start', bucket: bucket.name, bucketIndex: bucketIndex + 1, totalBuckets: allBuckets.length, message: `å¼€å§‹ä¸Šä¼ åˆ° ${bucket.name}...` })}\n\n`);
      
      // åˆ›å»º OSS å®¢æˆ·ç«¯
      const client = new OSS({
        region: bucket.region || ossConfig.region,
        accessKeyId: ossConfig.accessKeyId,
        accessKeySecret: ossConfig.accessKeySecret,
        bucket: bucket.name
      });
      
      // é€’å½’æ”¶é›†æ‰€æœ‰æ–‡ä»¶
      const collectFiles = (dirPath, prefix = '') => {
        const entries = fs.readdirSync(dirPath, { withFileTypes: true });
        let files = [];
        for (const entry of entries) {
          const fullPath = path.join(dirPath, entry.name);
          const ossPath = prefix ? `${prefix}/${entry.name}` : entry.name;
          if (entry.isDirectory()) {
            files = files.concat(collectFiles(fullPath, ossPath));
          } else {
            files.push({ fullPath, ossPath, fileName: entry.name });
          }
        }
        return files;
      };
      
      const allFiles = collectFiles(buildPath, bucket.prefix || '');
      let bucketUploadedFiles = 0;
      
      // å¹¶å‘ä¸Šä¼ 
      const CONCURRENCY = 15;
      let index = 0;
      
      const uploadBatch = async () => {
        const batch = allFiles.slice(index, index + CONCURRENCY);
        if (batch.length === 0) return;
        
        // æ˜¾ç¤ºæ­£åœ¨ä¸Šä¼ çš„æ–‡ä»¶
        batch.forEach(({ fileName }) => {
          res.write(`data: ${JSON.stringify({ type: 'uploading', file: fileName, bucket: bucket.name, bucketProgress: Math.round((bucketUploadedFiles / totalFiles) * 100), globalProgress: Math.round((globalUploadedFiles / (totalFiles * allBuckets.length)) * 100) })}\n\n`);
        });
        
        await Promise.all(batch.map(async ({ fullPath, ossPath, fileName }) => {
          try {
            const result = await client.put(ossPath, fullPath);
            bucketUploadedFiles++;
            globalUploadedFiles++;
            
            res.write(`data: ${JSON.stringify({ type: 'uploaded', file: fileName, bucket: bucket.name, url: result.url, bucketProgress: Math.round((bucketUploadedFiles / totalFiles) * 100), globalProgress: Math.round((globalUploadedFiles / (totalFiles * allBuckets.length)) * 100), uploaded: globalUploadedFiles, total: totalFiles * allBuckets.length })}\n\n`);
            
            allResults.push({ file: fileName, path: ossPath, url: result.url, status: 'success', bucket: bucket.name });
          } catch (err) {
            bucketUploadedFiles++;
            globalUploadedFiles++;
            res.write(`data: ${JSON.stringify({ type: 'failed', file: fileName, bucket: bucket.name, error: err.message, bucketProgress: Math.round((bucketUploadedFiles / totalFiles) * 100), globalProgress: Math.round((globalUploadedFiles / (totalFiles * allBuckets.length)) * 100), uploaded: globalUploadedFiles, total: totalFiles * allBuckets.length })}\n\n`);
            
            allResults.push({ file: fileName, path: ossPath, status: 'failed', error: err.message, bucket: bucket.name });
          }
        }));
        
        index += CONCURRENCY;
        if (index < allFiles.length) {
          await uploadBatch();
        }
      };
      
      if (allFiles.length > 0) {
        await uploadBatch();
      }
      
      // bucketä¸Šä¼ å®Œæˆ
      res.write(`data: ${JSON.stringify({ type: 'bucket_complete', bucket: bucket.name, bucketIndex: bucketIndex + 1, totalBuckets: allBuckets.length, message: `${bucket.name} ä¸Šä¼ å®Œæˆ` })}\n\n`);
    }
    
    const successCount = allResults.filter(r => r.status === 'success').length;
    const failCount = allResults.filter(r => r.status === 'failed').length;
    
    res.write(`data: ${JSON.stringify({ type: 'complete', uploaded: successCount, failed: failCount, results: allResults, message: 'ä¸Šä¼ å®Œæˆ' })}\n\n`);
    res.end();
    
  } catch (e) {
    console.error('OSS upload stream error:', e);
    res.write(`data: ${JSON.stringify({ type: 'error', message: e.message })}\n\n`);
    res.end();
  }
});

// æµå¼ä¸Šä¼ å‹ç¼©åŒ…åˆ° OSSï¼ˆå®æ—¶è¿›åº¦ï¼‰
app.get('/api/upload-zip-stream', async (req, res) => {
  try {
    const { projectName, path: projectPath, channelId, env, isBackup } = req.query;
    
    if (!projectName || !env) {
      return res.status(400).json({ ok: false, error: 'Missing required parameters' });
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ ok: false, error: 'Project not found' });
    }
    
    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // è¯»å– OSS è¿æ¥é…ç½®
    if (!fs.existsSync(OSS_CONFIG_PATH)) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'OSS connection config not found' })}\n\n`);
      res.end();
      return;
    }
    
    let ossConfig, allBuckets;
    try {
      const ossData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
      const ossConfigs = JSON.parse(ossData);
      
      if (!ossConfigs.connection) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: 'OSS connection config missing connection section' })}\n\n`);
        res.end();
        return;
      }
      
      ossConfig = ossConfigs.connection;
      console.log('OSS connection config loaded successfully');
      
      // è·å–æ‰€æœ‰å¯ç”¨ buckets
      const bucketConfig = getBucketConfig(ossConfigs, projectName, channelId, env);
      allBuckets = Array.isArray(bucketConfig) ? bucketConfig : [bucketConfig];
      
      if (!allBuckets || allBuckets.length === 0) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: 'No buckets configured for ${projectName}-${channelId}-${env}' })}\n\n`);
        res.end();
        return;
      }
      
      console.log(`Found ${allBuckets.length} buckets for ${projectName}-${channelId}-${env}`);
    } catch (e) {
      console.error('OSS config error:', e);
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'OSS config error: ${e.message}' })}\n\n`);
      res.end();
      return;
    }
    
    // æ£€æŸ¥æ„å»ºç›®å½•
    const buildPath = path.join(projectPath, 'build');
    if (!fs.existsSync(buildPath)) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'Build directory not found. Please build the project first.' })}\n\n`);
      res.end();
      return;
    }
    
    // æ£€æŸ¥buildç›®å½•æ˜¯å¦ä¸ºç©º
    const buildContents = fs.readdirSync(buildPath);
    if (buildContents.length === 0) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'Build directory is empty. Please build the project first.' })}\n\n`);
      res.end();
      return;
    }
    
    console.log(`Build directory exists: ${buildPath}, contents: ${buildContents.length} items`);
    
    // åˆ›å»ºå‹ç¼©åŒ…
    res.write(`data: ${JSON.stringify({ type: 'start', message: 'å¼€å§‹åˆ›å»ºå‹ç¼©åŒ…...' })}\n\n`);
    
    // ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å - ç®€åŒ–ä¸º YYYY-MM-DD.zip æ ¼å¼
    const zipFileName = `${new Date().toISOString().slice(0, 10)}.zip`;
    const zipFilePath = path.join(os.tmpdir(), zipFileName);
    
    console.log(`Creating zip file: ${zipFilePath}`);
    
    // åˆ›å»ºå‹ç¼©æµ
    const output = fs.createWriteStream(zipFilePath);
    const archive = archiver('zip', {
      zlib: { level: 9 } // æœ€é«˜å‹ç¼©çº§åˆ«
    });
    
    // å°†archiveè¿æ¥åˆ°è¾“å‡ºæµ
    archive.pipe(output);
    
    // ç›‘å¬å‹ç¼©äº‹ä»¶
    archive.on('error', (err) => {
      console.error('Archive error:', err);
      res.write(`data: ${JSON.stringify({ type: 'error', message: `å‹ç¼©å¤±è´¥: ${err.message}` })}\n\n`);
      res.end();
    });
    
    // ç›‘å¬å®Œæˆäº‹ä»¶ - ç§»é™¤asyncï¼Œç›´æ¥å‘é€å®Œæˆæ¶ˆæ¯
    archive.on('end', () => {
      console.log(`Compression completed, size: ${Math.round(archive.pointer() / 1024 / 1024)}MB`);
      res.write(`data: ${JSON.stringify({ type: 'compressed', message: `å‹ç¼©å®Œæˆï¼Œå¤§å°: ${Math.round(archive.pointer() / 1024 / 1024)}MB`, size: archive.pointer() })}\n\n`);
      
      // å¼‚æ­¥å¼€å§‹ä¸Šä¼ è¿‡ç¨‹
      setImmediate(() => startUploadProcess());
    });
    
    // æ·»åŠ ä¸€äº›è°ƒè¯•äº‹ä»¶
    archive.on('warning', (err) => {
      console.warn('Archive warning:', err);
    });
    
    archive.on('progress', (progress) => {
      console.log('Archive progress:', progress);
    });
    
    // åˆ†ç¦»ä¸Šä¼ é€»è¾‘åˆ°å•ç‹¬çš„å‡½æ•°
    const startUploadProcess = async () => {
      try {
        const allResults = []; // åˆå§‹åŒ–ç»“æœæ•°ç»„
        
        // ä¸Šä¼ åˆ°æ¯ä¸ª bucket
        for (let bucketIndex = 0; bucketIndex < allBuckets.length; bucketIndex++) {
          const bucket = allBuckets[bucketIndex];
          if (bucket.enabled === false) continue;
          
          // ä¸ºæ¯ä¸ªbucketå‘é€å¼€å§‹æ¶ˆæ¯
          res.write(`data: ${JSON.stringify({ type: 'bucket_start', bucket: bucket.name, bucketIndex: bucketIndex + 1, totalBuckets: allBuckets.length, message: `å¼€å§‹ä¸Šä¼ åˆ° ${bucket.name}...` })}\n\n`);
          
          // åˆ›å»º OSS å®¢æˆ·ç«¯
          const client = new OSS({
            region: bucket.region || ossConfig.region,
            accessKeyId: ossConfig.accessKeyId,
            accessKeySecret: ossConfig.accessKeySecret,
            bucket: bucket.name
          });
          
          // ä¸Šä¼ å‹ç¼©åŒ… - å¤‡ä»½æ–‡ä»¶æ”¾åœ¨"ä»¥å¾€ç‰ˆæœ¬"ç›®å½•ä¸‹
          const backupPrefix = bucket.prefix || 'ä»¥å¾€ç‰ˆæœ¬';
          const ossPath = `${backupPrefix}/${zipFileName}`;
          
          res.write(`data: ${JSON.stringify({ type: 'uploading', file: zipFileName, bucket: bucket.name, bucketProgress: 0, globalProgress: Math.round(((bucketIndex * 100) / allBuckets.length)) })}\n\n`);
          
          try {
            const result = await client.put(ossPath, zipFilePath);
            
            res.write(`data: ${JSON.stringify({ type: 'uploaded', file: zipFileName, bucket: bucket.name, url: result.url, bucketProgress: 100, globalProgress: Math.round(((bucketIndex + 1) * 100) / allBuckets.length), uploaded: bucketIndex + 1, total: allBuckets.length })}\n\n`);
            
            allResults.push({ file: zipFileName, path: ossPath, url: result.url, status: 'success', bucket: bucket.name });
          } catch (err) {
            res.write(`data: ${JSON.stringify({ type: 'failed', file: zipFileName, bucket: bucket.name, error: err.message, bucketProgress: 100, globalProgress: Math.round(((bucketIndex + 1) * 100) / allBuckets.length), uploaded: bucketIndex + 1, total: allBuckets.length })}\n\n`);
            
            allResults.push({ file: zipFileName, path: ossPath, status: 'failed', error: err.message, bucket: bucket.name });
          }
          
          // bucketä¸Šä¼ å®Œæˆ
          res.write(`data: ${JSON.stringify({ type: 'bucket_complete', bucket: bucket.name, bucketIndex: bucketIndex + 1, totalBuckets: allBuckets.length, message: `${bucket.name} ä¸Šä¼ å®Œæˆ` })}\n\n`);
        }
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try {
          fs.unlinkSync(zipFilePath);
        } catch (cleanupErr) {
          console.warn('Failed to cleanup temp zip file:', cleanupErr.message);
        }
        
        const successCount = allResults.filter(r => r.status === 'success').length;
        const failCount = allResults.filter(r => r.status === 'failed').length;
        
        // ç”Ÿäº§ç¯å¢ƒä¸Šä¼ å®Œæˆåçš„è‡ªåŠ¨æ‰§è¡Œ
        if (env === 'prod' && successCount > 0) {
          try {
            await executePostDeploymentTasks(projectName, allResults, zipFileName);
          } catch (taskErr) {
            console.warn('Post-deployment tasks failed:', taskErr.message);
            // ä¸å½±å“ä¸Šä¼ æˆåŠŸçš„ç»“æœï¼Œåªè®°å½•è­¦å‘Š
          }
        }
        
        res.write(`data: ${JSON.stringify({ type: 'complete', uploaded: successCount, failed: failCount, results: allResults, message: env === 'prod' ? 'ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å®Œæˆ' : 'å‹ç¼©åŒ…ä¸Šä¼ å®Œæˆ', zipFile: zipFileName })}\n\n`);
        res.end();
        
      } catch (uploadErr) {
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try {
          fs.unlinkSync(zipFilePath);
        } catch (cleanupErr) {
          console.warn('Failed to cleanup temp zip file:', cleanupErr.message);
        }
        
        res.write(`data: ${JSON.stringify({ type: 'error', message: uploadErr.message })}\n\n`);
        res.end();
      }
    };
    
    // å°†æ„å»ºç›®å½•æ·»åŠ åˆ°å‹ç¼©åŒ…
    console.log(`Adding directory to archive: ${buildPath}`);
    archive.directory(buildPath, false);
    
    // å®Œæˆå‹ç¼©
    console.log('Finalizing archive...');
    archive.finalize();
    
  } catch (e) {
    console.error('OSS zip upload stream error:', e);
    res.write(`data: ${JSON.stringify({ type: 'error', message: e.message })}\n\n`);
    res.end();
  }
});

// æŒ‰æ¸ é“å’Œç¯å¢ƒä¸Šä¼ åˆ° OSS
app.post('/api/oss/upload-channel', async (req, res) => {
  try {
    const { projectName, path: projectPath, channelId, env, buckets: selectedBuckets, buildFirst, backupFirst } = req.body;
    
    if (!projectName || !channelId || !env) {
      return res.status(400).json({ ok: false, error: 'Missing required parameters' });
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ ok: false, error: 'Project not found' });
    }
    
    // è¯»å– OSS è¿æ¥é…ç½®
    if (!fs.existsSync(OSS_CONFIG_PATH)) {
      return res.status(500).json({ ok: false, error: 'OSS connection config not found' });
    }
    
    let ossConfig, allBuckets;
    try {
      const ossData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
      const ossConfigs = JSON.parse(ossData);
      ossConfig = ossConfigs.connection;
      
      // è·å–æ‰€æœ‰å¯ç”¨ buckets
      const bucketConfig = getBucketConfig(ossConfigs, projectName, channelId, env);
      allBuckets = Array.isArray(bucketConfig) ? bucketConfig : [bucketConfig];
      
      if (!allBuckets || allBuckets.length === 0) {
        return res.status(404).json({ ok: false, error: `No buckets configured for ${projectName}-${channelId}-${env}` });
      }
    } catch (e) {
      return res.status(500).json({ ok: false, error: 'Failed to load OSS config: ' + e.message });
    }
    
    // è¿‡æ»¤é€‰ä¸­çš„ buckets
    const bucketsToUpload = selectedBuckets && selectedBuckets.length > 0 
      ? allBuckets.filter(b => selectedBuckets.includes(b.name))
      : allBuckets; // å¦‚æœæ²¡æœ‰é€‰æ‹©ï¼Œé»˜è®¤ä¸Šä¼ æ‰€æœ‰
    
    if (bucketsToUpload.length === 0) {
      return res.status(400).json({ ok: false, error: 'No buckets selected' });
    }
    
    // æ£€æŸ¥æ„å»ºç›®å½•
    const buildPath = path.join(projectPath, 'build');
    if (!fs.existsSync(buildPath)) {
      return res.status(404).json({ ok: false, error: 'Build directory not found. Please build first.' });
    }
    
    // åŠ¨æ€å¯¼å…¥ ali-oss
    const OSS = (await import('ali-oss')).default;
    
    const allResults = [];
    
    // ä¸Šä¼ åˆ°æ¯ä¸ªé€‰ä¸­çš„ bucket
    for (const bucket of bucketsToUpload) {
      if (bucket.enabled === false) continue;
      
      // åˆ›å»º OSS å®¢æˆ·ç«¯
      const client = new OSS({
        region: bucket.region || ossConfig.region,
        accessKeyId: ossConfig.accessKeyId,
        accessKeySecret: ossConfig.accessKeySecret,
        bucket: bucket.name
      });
      
      // ä¸Šä¼ æ–‡ä»¶
      const uploadDir = async (dirPath, prefix = '') => {
        const entries = fs.readdirSync(dirPath, { withFileTypes: true });
        const results = [];
        
        for (const entry of entries) {
          const fullPath = path.join(dirPath, entry.name);
          const ossPath = prefix ? `${prefix}/${entry.name}` : entry.name;
          
          if (entry.isDirectory()) {
            const subResults = await uploadDir(fullPath, ossPath);
            results.push(...subResults);
          } else {
            try {
              const result = await client.put(ossPath, fullPath);
              results.push({ file: entry.name, path: ossPath, url: result.url, status: 'success', bucket: bucket.name });
            } catch (err) {
              results.push({ file: entry.name, path: ossPath, status: 'failed', error: err.message, bucket: bucket.name });
            }
          }
        }
        
        return results;
      };
      
      const uploadResults = await uploadDir(buildPath, bucket.prefix || '');
      allResults.push(...uploadResults);
    }
    
    const successCount = allResults.filter(r => r.status === 'success').length;
    const failCount = allResults.filter(r => r.status === 'failed').length;
    
    res.json({ 
      ok: true, 
      buckets: bucketsToUpload.map(b => b.name),
      channel: channelId,
      env,
      uploaded: successCount,
      failed: failCount,
      results: allResults
    });
  } catch (e) {
    console.error('OSS upload error:', e);
    res.status(500).json({ ok: false, error: e.message, stack: e.stack });
  }
});

// ç®€å•é¡¹ç›®ä¸Šä¼ ï¼ˆæ— æ¸ é“ï¼Œä½†æœ‰ç¯å¢ƒåŒºåˆ†ï¼‰
app.post('/api/oss/upload-simple', async (req, res) => {
  try {
    const { projectName, path: projectPath, env, bucket: bucketName } = req.body;
    
    if (!projectName || !env || !bucketName) {
      return res.status(400).json({ ok: false, error: 'Missing required parameters' });
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ ok: false, error: 'Project not found' });
    }
    
    // æ£€æŸ¥ bucket æ˜¯å¦ä¸ºå ä½ç¬¦
    if (bucketName.includes('placeholder')) {
      return res.status(400).json({ ok: false, error: `Bucket ${bucketName} å°šæœªé…ç½®ï¼Œè¯·å…ˆé…ç½®å®é™…çš„ bucket åç§°` });
    }
    
    // è¯»å– OSS è¿æ¥é…ç½®ï¼ˆæ–°ç»“æ„ï¼‰
    if (!fs.existsSync(OSS_CONFIG_PATH)) {
      return res.status(500).json({ ok: false, error: 'OSS connection config not found' });
    }
    
    let ossConfig, bucketConfig;
    try {
      const ossData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
      const ossConfigs = JSON.parse(ossData);
      ossConfig = ossConfigs.connection;
      
      // ä½¿ç”¨æ–°çš„æŸ¥æ‰¾å‡½æ•°
      bucketConfig = getBucketConfig(ossConfigs, projectName, null, env);
      
      if (!bucketConfig) {
        return res.status(404).json({ ok: false, error: `Bucket config not found for ${projectName}-${env}` });
      }
      
      // å¦‚æœæ˜¯æ•°ç»„ï¼ˆå¤šä¸ªç”Ÿäº§ç¯å¢ƒï¼‰ï¼Œéœ€è¦åŒ¹é…æŒ‡å®šçš„ bucket
      if (Array.isArray(bucketConfig)) {
        bucketConfig = bucketConfig.find(b => b.name === bucketName);
        if (!bucketConfig) {
          return res.status(404).json({ ok: false, error: `Bucket ${bucketName} not found` });
        }
      }
      
      if (bucketConfig.enabled === false) {
        return res.status(400).json({ ok: false, error: `Bucket is disabled (æœªé…ç½®)` });
      }
    } catch (e) {
      return res.status(500).json({ ok: false, error: 'Failed to load OSS config: ' + e.message });
    }
    
    // æ£€æŸ¥æ„å»ºç›®å½•
    const buildPath = path.join(projectPath, 'build');
    if (!fs.existsSync(buildPath)) {
      return res.status(404).json({ ok: false, error: 'Build directory not found. Please build first.' });
    }
    
    // åŠ¨æ€å¯¼å…¥ ali-oss
    const OSS = (await import('ali-oss')).default;
    
    // åˆ›å»º OSS å®¢æˆ·ç«¯ï¼ˆå•é¡¹ç›®ä¸Šä¼ ï¼‰
    const client = new OSS({
      region: ossConfig.region,
      accessKeyId: ossConfig.accessKeyId,
      accessKeySecret: ossConfig.accessKeySecret,
      bucket: bucketConfig.name
    });
    
    // ä¸Šä¼ æ–‡ä»¶
    const uploadDir = async (dirPath, prefix = '') => {
      const entries = fs.readdirSync(dirPath, { withFileTypes: true });
      const results = [];
      
      for (const entry of entries) {
        const fullPath = path.join(dirPath, entry.name);
        const ossPath = prefix ? `${prefix}/${entry.name}` : entry.name;
        
        if (entry.isDirectory()) {
          const subResults = await uploadDir(fullPath, ossPath);
          results.push(...subResults);
        } else {
          try {
            const result = await client.put(ossPath, fullPath);
            results.push({ file: entry.name, path: ossPath, url: result.url, status: 'success' });
          } catch (err) {
            results.push({ file: entry.name, path: ossPath, status: 'failed', error: err.message });
          }
        }
      }
      
      return results;
    };
    
    const uploadResults = await uploadDir(buildPath, bucketConfig.prefix || '');
    
    const successCount = uploadResults.filter(r => r.status === 'success').length;
    const failCount = uploadResults.filter(r => r.status === 'failed').length;
    
    res.json({ 
      ok: true, 
      bucket: bucketConfig.name,
      project: projectName,
      env,
      uploaded: successCount,
      failed: failCount,
      url: bucketConfig.url || `https://${bucketConfig.name}.oss-cn-hangzhou.aliyuncs.com`,
      results: uploadResults
    });
  } catch (e) {
    console.error('OSS upload error:', e);
    res.status(500).json({ ok: false, error: e.message, stack: e.stack });
  }
});

// æµå¼ä¸Šä¼ åˆ° OSSï¼ˆå®æ—¶è¿›åº¦ï¼‰
app.post('/api/oss/upload-stream', async (req, res) => {
  try {
    const { projectName, path: projectPath, env, bucket: bucketName } = req.body;
    
    if (!projectName || !env || !bucketName) {
      return res.status(400).json({ error: 'Missing required parameters' });
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ error: 'Project not found' });
    }
    
    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // æ£€æŸ¥ bucket æ˜¯å¦ä¸ºå ä½ç¬¦
    if (bucketName.includes('placeholder')) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: `Bucket ${bucketName} å°šæœªé…ç½®` })}\n\n`);
      res.end();
      return;
    }
    
    // è¯»å– OSS é…ç½®
    let ossConfig, bucketConfig;
    try {
      const ossData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
      const ossConfigs = JSON.parse(ossData);
      ossConfig = ossConfigs.connection;
      
      bucketConfig = getBucketConfig(ossConfigs, projectName, null, env);
      
      if (!bucketConfig) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: `Bucket config not found` })}\n\n`);
        res.end();
        return;
      }
      
      if (Array.isArray(bucketConfig)) {
        bucketConfig = bucketConfig.find(b => b.name === bucketName);
        if (!bucketConfig) {
          res.write(`data: ${JSON.stringify({ type: 'error', message: `Bucket ${bucketName} not found` })}\n\n`);
          res.end();
          return;
        }
      }
      
      if (bucketConfig.enabled === false) {
        res.write(`data: ${JSON.stringify({ type: 'error', message: 'Bucket is disabled' })}\n\n`);
        res.end();
        return;
      }
    } catch (e) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'Failed to load OSS config: ' + e.message })}\n\n`);
      res.end();
      return;
    }
    
    // æ£€æŸ¥æ„å»ºç›®å½•
    const buildPath = path.join(projectPath, 'build');
    if (!fs.existsSync(buildPath)) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'Build directory not found' })}\n\n`);
      res.end();
      return;
    }
    
    // æ£€æŸ¥ build ç›®å½•æ˜¯å¦ä¸ºç©º
    const shouldIgnoreFile = (filename) => {
      const ignoreList = ['.DS_Store', 'Thumbs.db', '.gitkeep', '.gitignore'];
      return ignoreList.includes(filename);
    };
    
    const countFiles = (dir) => {
      try {
        const entries = fs.readdirSync(dir, { withFileTypes: true });
        let count = 0;
        for (const entry of entries) {
          if (shouldIgnoreFile(entry.name)) {
            continue; // è·³è¿‡ç³»ç»Ÿæ–‡ä»¶
          }
          if (entry.isDirectory()) {
            count += countFiles(path.join(dir, entry.name));
          } else {
            count++;
          }
        }
        return count;
      } catch (e) {
        return 0;
      }
    };
    
    const fileCount = countFiles(buildPath);
    if (fileCount === 0) {
      res.write(`data: ${JSON.stringify({ type: 'error', message: 'Build directory is empty' })}\n\n`);
      res.end();
      return;
    }
    
    res.write(`data: ${JSON.stringify({ type: 'log', message: `å¼€å§‹ä¸Šä¼ åˆ° ${bucketConfig.name}...` })}\n\n`);
    
    // åŠ¨æ€å¯¼å…¥ ali-oss
    const OSS = (await import('ali-oss')).default;
    
    const client = new OSS({
      region: ossConfig.region,
      accessKeyId: ossConfig.accessKeyId,
      accessKeySecret: ossConfig.accessKeySecret,
      bucket: bucketConfig.name
    });
    
    let successCount = 0;
    let failCount = 0;
    let totalFiles = 0;
    
    // é€’å½’æ”¶é›†æ‰€æœ‰æ–‡ä»¶
    const collectFiles = (dirPath, prefix = '') => {
      const entries = fs.readdirSync(dirPath, { withFileTypes: true });
      let files = [];
      for (const entry of entries) {
        if (shouldIgnoreFile(entry.name)) continue;
        const fullPath = path.join(dirPath, entry.name);
        const ossPath = prefix ? `${prefix}/${entry.name}` : entry.name;
        if (entry.isDirectory()) {
          files = files.concat(collectFiles(fullPath, ossPath));
        } else {
          files.push({ fullPath, ossPath });
        }
      }
      return files;
    };

    const allFiles = collectFiles(buildPath, bucketConfig.prefix || '');
    totalFiles = allFiles.length;

    // å¹¶å‘ä¸Šä¼ 
  const CONCURRENCY = 15;
    let index = 0;
    let completedCount = 0;
    
    async function uploadBatch() {
      const batch = allFiles.slice(index, index + CONCURRENCY);
      if (batch.length === 0) return;
      
      // æ˜¾ç¤ºæ­£åœ¨ä¸Šä¼ çš„æ–‡ä»¶
      batch.forEach(({ ossPath }) => {
        res.write(`data: ${JSON.stringify({ type: 'uploading', file: ossPath, current: completedCount + 1 })}\n\n`);
      });
      
      await Promise.all(batch.map(async ({ fullPath, ossPath }) => {
        try {
          await client.put(ossPath, fullPath);
          successCount++;
          completedCount++;
          res.write(`data: ${JSON.stringify({ type: 'success', file: ossPath, current: successCount + failCount, total: totalFiles })}\n\n`);
        } catch (err) {
          failCount++;
          completedCount++;
          res.write(`data: ${JSON.stringify({ type: 'error', file: ossPath, message: err.message })}\n\n`);
        }
      }));
      
      index += CONCURRENCY;
      if (index < allFiles.length) {
        await uploadBatch();
      }
    }

    if (allFiles.length > 0) {
      await uploadBatch();
    }
    
    res.write(`data: ${JSON.stringify({ 
      type: 'complete', 
      message: 'ä¸Šä¼ å®Œæˆ',
      uploaded: successCount,
      failed: failCount,
      url: bucketConfig.url || `https://${bucketConfig.name}.oss-cn-hangzhou.aliyuncs.com`
    })}\n\n`);
    
    res.end();
    
  } catch (e) {
    console.error('OSS upload stream error:', e);
    res.write(`data: ${JSON.stringify({ type: 'error', message: e.message })}\n\n`);
    res.end();
  }
});

// æ— æ¸ é“é¡¹ç›®çš„é»˜è®¤ä¸Šä¼ ï¼ˆå·²åºŸå¼ƒï¼‰
app.post('/api/oss/upload', async (req, res) => {
  try {
    const { projectName, path: projectPath } = req.body;
    
    if (!projectName) {
      return res.status(400).json({ ok: false, error: 'Missing projectName' });
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ ok: false, error: 'Project not found' });
    }
    
    // å·²åºŸå¼ƒï¼Œä½¿ç”¨ upload-simple ä»£æ›¿
    res.status(501).json({ ok: false, error: 'Please use /api/oss/upload-simple with environment selection.' });
  } catch (e) {
    res.status(500).json({ ok: false, error: e.message });
  }
});

// å¤åˆ¶æ–‡ä»¶åˆ° agent-pro å¹¶ git push
app.post('/api/copy-and-push', async (req, res) => {
  try {
    const { sourcePath, targetProjectPath, commitMessage } = req.body;
    
    if (!sourcePath || !targetProjectPath) {
      return res.status(400).json({ ok: false, error: 'Missing required parameters' });
    }
    
    const sourceDir = path.join(sourcePath, 'build');
    
    // æ£€æŸ¥æºç›®å½•æ˜¯å¦å­˜åœ¨
    if (!fs.existsSync(sourceDir)) {
      return res.status(400).json({ ok: false, error: 'Build directory not found' });
    }
    
    // æ£€æŸ¥ç›®æ ‡é¡¹ç›®æ˜¯å¦å­˜åœ¨
    if (!fs.existsSync(targetProjectPath)) {
      return res.status(400).json({ ok: false, error: 'Target project not found' });
    }
    
    // å¤åˆ¶æ–‡ä»¶
    const copyRecursive = (src, dest) => {
      const exists = fs.existsSync(src);
      const stats = exists && fs.statSync(src);
      const isDirectory = exists && stats.isDirectory();
      
      if (isDirectory) {
        if (!fs.existsSync(dest)) {
          fs.mkdirSync(dest, { recursive: true });
        }
        fs.readdirSync(src).forEach(childItemName => {
          copyRecursive(
            path.join(src, childItemName),
            path.join(dest, childItemName)
          );
        });
      } else {
        fs.copyFileSync(src, dest);
      }
    };
    
    // åˆ é™¤ç›®æ ‡ç›®å½•ä¸­çš„æ—§æ–‡ä»¶ï¼ˆé™¤äº† .git ç›®å½•ï¼‰
    const cleanTarget = (targetPath) => {
      if (!fs.existsSync(targetPath)) return;
      
      const items = fs.readdirSync(targetPath);
      for (const item of items) {
        if (item === '.git') continue; // ä¿ç•™ .git ç›®å½•
        
        const itemPath = path.join(targetPath, item);
        const stats = fs.statSync(itemPath);
        
        if (stats.isDirectory()) {
          fs.rmSync(itemPath, { recursive: true, force: true });
        } else {
          fs.unlinkSync(itemPath);
        }
      }
    };
    
    // æ¸…ç†ç›®æ ‡ç›®å½•
    cleanTarget(targetProjectPath);
    
    // å¤åˆ¶æ‰€æœ‰æ–‡ä»¶
    const files = fs.readdirSync(sourceDir);
    let copiedCount = 0;
    
    for (const file of files) {
      const srcFile = path.join(sourceDir, file);
      const destFile = path.join(targetProjectPath, file);
      copyRecursive(srcFile, destFile);
      copiedCount++;
    }
    
    // Git æ“ä½œ
    const git = simpleGit(targetProjectPath);
    
    // æ·»åŠ æ‰€æœ‰æ–‡ä»¶
    await git.add('.');
    
    // æ£€æŸ¥æ˜¯å¦æœ‰æ”¹åŠ¨
    const status = await git.status();
    
    if (status.files.length === 0) {
      return res.json({
        ok: true,
        message: 'No changes to commit',
        copiedFiles: copiedCount,
        pushed: false
      });
    }
    
    // æäº¤
    const message = commitMessage || `Update from react-agent-website build at ${new Date().toLocaleString('zh-CN')}`;
    await git.commit(message);
    
    // Push
    await git.push('origin', 'main');
    
    res.json({
      ok: true,
      message: 'Files copied and pushed successfully',
      copiedFiles: copiedCount,
      changedFiles: status.files.length,
      pushed: true
    });
    
  } catch (e) {
    console.error('Copy and push error:', e);
    res.status(500).json({ ok: false, error: e.message });
  }
});

// å‹ç¼© build æ–‡ä»¶å¤¹å¹¶ä¸Šä¼ åˆ° OSS çš„"ä»¥å¾€ç‰ˆæœ¬"ç›®å½•
app.post('/api/backup-build', async (req, res) => {
  try {
    const { projectName, projectPath, bucketName } = req.body;
    
    if (!projectName || !projectPath || !bucketName) {
      return res.status(400).json({ ok: false, error: 'Missing required parameters' });
    }
    
    const buildPath = path.join(projectPath, 'build');
    
    // ç”Ÿæˆæ—¥æœŸæ ¼å¼çš„æ–‡ä»¶å YYYY-MM-DD
    const now = new Date();
    const dateStr = `${now.getFullYear()}-${String(now.getMonth() + 1).padStart(2, '0')}-${String(now.getDate()).padStart(2, '0')}`;
    const zipFileName = `${dateStr}.zip`;
    const tempZipPath = path.join(os.tmpdir(), `${projectName}-${dateStr}-${Date.now()}.zip`);
    
    // åˆ›å»ºå‹ç¼©æ–‡ä»¶
    await new Promise((resolve, reject) => {
      const output = fs.createWriteStream(tempZipPath);
      const archive = archiver('zip', { zlib: { level: 9 } });
      
      output.on('close', () => {
        console.log(`Archive created: ${archive.pointer()} bytes`);
        resolve();
      });
      
      archive.on('error', (err) => {
        reject(err);
      });
      
      archive.pipe(output);
      archive.directory(buildPath, false);
      archive.finalize();
    });
    
    // è¯»å– OSS é…ç½®
    const ossConfigData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
    const ossConfigs = JSON.parse(ossConfigData);
    
    if (!ossConfigs.connection) {
      return res.status(500).json({ ok: false, error: 'OSS connection config not found' });
    }
    
    // å¯¼å…¥ ali-oss
    const OSS = (await import('ali-oss')).default;
    
    // åˆ›å»º OSS å®¢æˆ·ç«¯
    const client = new OSS({
      region: ossConfigs.connection.region,
      accessKeyId: ossConfigs.connection.accessKeyId,
      accessKeySecret: ossConfigs.connection.accessKeySecret,
      bucket: bucketName
    });
    
    // ä¸Šä¼ åˆ° OSS çš„"ä»¥å¾€ç‰ˆæœ¬"ç›®å½•
    const ossPath = `ä»¥å¾€ç‰ˆæœ¬/${zipFileName}`;
    const result = await client.put(ossPath, tempZipPath);
    
    // è·å–æ–‡ä»¶å¤§å°ï¼ˆåœ¨åˆ é™¤å‰ï¼‰
    const zipStats = fs.statSync(tempZipPath);
    const fileSizeInMB = (zipStats.size / (1024 * 1024)).toFixed(2);
    
    // åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    fs.unlinkSync(tempZipPath);
    
    res.json({
      ok: true,
      message: 'Build backup uploaded successfully',
      fileName: zipFileName,
      ossPath: ossPath,
      url: result.url,
      size: fileSizeInMB + ' MB'
    });
    
  } catch (e) {
    console.error('Backup build error:', e);
    res.status(500).json({ ok: false, error: e.message });
  }
});

// è·å– bucket ä¿¡æ¯ï¼ˆç”¨äºå¤šæ¸ é“é¡¹ç›®å¤‡ä»½ï¼‰
app.post('/api/oss/get-bucket-info', async (req, res) => {
  try {
    const { projectName, channelId, env } = req.body;
    
    const ossConfigData = fs.readFileSync(OSS_CONFIG_PATH, 'utf-8');
    const ossConfigs = JSON.parse(ossConfigData);
    
    const bucketConfig = getBucketConfig(ossConfigs, projectName, channelId, env);
    
    if (!bucketConfig) {
      return res.status(404).json({ error: 'Bucket config not found' });
    }
    
    const buckets = Array.isArray(bucketConfig) ? bucketConfig : [bucketConfig];
    res.json({ buckets });
    
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// æ¸…ç©ºbuildæ–‡ä»¶å¤¹
app.post('/api/clear-build', async (req, res) => {
  try {
    const { projectName, path: projectPathParam } = req.body;
    
    if (!projectName && !projectPathParam) {
      return res.status(400).json({ error: 'Missing projectName or path' });
    }
    
    let projectPath = projectPathParam || path.join(DEFAULT_DIR, projectName);
    
    // å¤„ç† ~ è·¯å¾„
    if (projectPath.startsWith('~')) {
      const homeDir = require('os').homedir();
      projectPath = path.join(homeDir, projectPath.slice(1));
    }
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ error: 'Project not found: ' + projectPath });
    }
    
    const buildPath = path.join(projectPath, 'build');
    
    if (fs.existsSync(buildPath)) {
      try {
        // é€’å½’åˆ é™¤buildç›®å½•å†…å®¹
        const { execSync } = await import('child_process');
        execSync(`rm -rf "${buildPath}"/*`, { cwd: projectPath });
        res.json({ success: true, message: 'buildæ–‡ä»¶å¤¹å·²æ¸…ç©º' });
      } catch (err) {
        res.status(500).json({ error: 'æ¸…ç©ºbuildæ–‡ä»¶å¤¹å¤±è´¥: ' + err.message });
      }
    } else {
      res.json({ success: true, message: 'buildæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç©º' });
    }
    
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å®Œæˆåçš„è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡
async function executePostDeploymentTasks(projectName, uploadResults, zipFileName) {
  console.log(`ğŸ”„ å¼€å§‹æ‰§è¡Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²åä»»åŠ¡ - é¡¹ç›®: ${projectName}`);
  
  const tasks = [];
  
  try {
    // ä»»åŠ¡1: å‘é€éƒ¨ç½²å®Œæˆé€šçŸ¥
    tasks.push({
      name: 'éƒ¨ç½²é€šçŸ¥',
      status: 'running',
      result: await sendDeploymentNotification(projectName, uploadResults, zipFileName)
    });
    
    // ä»»åŠ¡2: æ›´æ–°é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯
    tasks.push({
      name: 'ç‰ˆæœ¬æ›´æ–°',
      status: 'running', 
      result: await updateProjectVersion(projectName, zipFileName)
    });
    
    // ä»»åŠ¡3: æ‰§è¡Œéƒ¨ç½²è„šæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    tasks.push({
      name: 'éƒ¨ç½²è„šæœ¬',
      status: 'running',
      result: await executeDeploymentScript(projectName)
    });
    
    // ä»»åŠ¡4: æ¸…ç†æ—§ç‰ˆæœ¬æ–‡ä»¶
    tasks.push({
      name: 'æ¸…ç†ç¼“å­˜',
      status: 'running',
      result: await cleanupOldVersions(projectName)
    });
    
    console.log(`âœ… ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²åä»»åŠ¡å®Œæˆ - é¡¹ç›®: ${projectName}`);
    return { success: true, tasks };
    
  } catch (error) {
    console.error(`âŒ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²åä»»åŠ¡å¤±è´¥ - é¡¹ç›®: ${projectName}`, error);
    return { success: false, error: error.message, tasks };
  }
}

// å‘é€éƒ¨ç½²å®Œæˆé€šçŸ¥
async function sendDeploymentNotification(projectName, uploadResults, zipFileName) {
  try {
    const timestamp = new Date().toLocaleString('zh-CN');
    const successCount = uploadResults.filter(r => r.status === 'success').length;
    const totalCount = uploadResults.length;
    
    const message = `ğŸš€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å®Œæˆ\n\nğŸ“¦ é¡¹ç›®: ${projectName}\nğŸ“ æ–‡ä»¶: ${zipFileName}\nâ° æ—¶é—´: ${timestamp}\nâœ… æˆåŠŸ: ${successCount}/${totalCount} ä¸ªå­˜å‚¨æ¡¶\n\nå­˜å‚¨è¯¦æƒ…:\n${uploadResults.map(r => `${r.bucket}: ${r.status === 'success' ? 'âœ…' : 'âŒ'} ${r.url || r.error}`).join('\n')}`;
    
    // è¿™é‡Œå¯ä»¥é›†æˆå„ç§é€šçŸ¥æœåŠ¡ï¼Œå¦‚å¾®ä¿¡ã€é’‰é’‰ã€é‚®ä»¶ç­‰
    // æš‚æ—¶è®°å½•åˆ°æ§åˆ¶å°ï¼Œåç»­å¯ä»¥æ‰©å±•
    console.log('ğŸ“¢ éƒ¨ç½²é€šçŸ¥:', message);
    
    // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å®é™…çš„é€šçŸ¥å‘é€é€»è¾‘
    // await sendWechatNotification(message);
    // await sendEmailNotification(message);
    
    return { success: true, message: 'é€šçŸ¥å‘é€æˆåŠŸ' };
  } catch (error) {
    throw new Error(`å‘é€é€šçŸ¥å¤±è´¥: ${error.message}`);
  }
}

// æ›´æ–°é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯
async function updateProjectVersion(projectName, zipFileName) {
  try {
    const versionFile = path.join(__dirname, 'project-versions.json');
    
    let versions = {};
    if (fs.existsSync(versionFile)) {
      versions = JSON.parse(fs.readFileSync(versionFile, 'utf-8'));
    }
    
    versions[projectName] = {
      lastDeployed: new Date().toISOString(),
      zipFile: zipFileName,
      environment: 'prod',
      timestamp: Date.now()
    };
    
    fs.writeFileSync(versionFile, JSON.stringify(versions, null, 2));
    
    return { success: true, message: 'ç‰ˆæœ¬ä¿¡æ¯å·²æ›´æ–°' };
  } catch (error) {
    throw new Error(`æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: ${error.message}`);
  }
}

// æ‰§è¡Œéƒ¨ç½²è„šæœ¬
async function executeDeploymentScript(projectName) {
  try {
    const projectPath = path.join(DEFAULT_DIR, projectName);
    const deployScript = path.join(projectPath, 'deploy.sh');
    const deployScriptAlt = path.join(projectPath, 'scripts', 'deploy.sh');
    
    let scriptPath = null;
    if (fs.existsSync(deployScript)) {
      scriptPath = deployScript;
    } else if (fs.existsSync(deployScriptAlt)) {
      scriptPath = deployScriptAlt;
    }
    
    if (scriptPath) {
      const { execSync } = await import('child_process');
      const result = execSync(`bash "${scriptPath}"`, { 
        cwd: projectPath,
        encoding: 'utf-8',
        timeout: 30000 // 30ç§’è¶…æ—¶
      });
      
      console.log(`ğŸ“œ éƒ¨ç½²è„šæœ¬æ‰§è¡Œç»“æœ: ${projectName}`, result);
      return { success: true, message: 'éƒ¨ç½²è„šæœ¬æ‰§è¡ŒæˆåŠŸ', output: result };
    } else {
      return { success: true, message: 'æœªæ‰¾åˆ°éƒ¨ç½²è„šæœ¬ï¼Œè·³è¿‡æ‰§è¡Œ' };
    }
  } catch (error) {
    throw new Error(`æ‰§è¡Œéƒ¨ç½²è„šæœ¬å¤±è´¥: ${error.message}`);
  }
}

// æ¸…ç†æ—§ç‰ˆæœ¬æ–‡ä»¶
async function cleanupOldVersions(projectName) {
  try {
    const versionFile = path.join(__dirname, 'project-versions.json');
    
    if (!fs.existsSync(versionFile)) {
      return { success: true, message: 'æ— ç‰ˆæœ¬æ–‡ä»¶éœ€è¦æ¸…ç†' };
    }
    
    const versions = JSON.parse(fs.readFileSync(versionFile, 'utf-8'));
    const projectVersions = versions[projectName];
    
    if (!projectVersions) {
      return { success: true, message: 'æ— é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯' };
    }
    
    // ä¿ç•™æœ€è¿‘5ä¸ªç‰ˆæœ¬ï¼Œæ¸…ç†æ›´æ—§çš„
    const maxVersions = 5;
    const sortedVersions = Object.entries(projectVersions)
      .sort(([,a], [,b]) => b.timestamp - a.timestamp)
      .slice(maxVersions);
    
    if (sortedVersions.length > 0) {
      console.log(`ğŸ§¹ æ¸…ç†æ—§ç‰ˆæœ¬æ–‡ä»¶: ${projectName}`, sortedVersions.map(([key]) => key));
      // è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æ–‡ä»¶æ¸…ç†é€»è¾‘
      // æ¯”å¦‚åˆ é™¤OSSä¸Šçš„æ—§ç‰ˆæœ¬æ–‡ä»¶
    }
    
    return { success: true, message: `å·²æ¸…ç†æ—§ç‰ˆæœ¬ï¼Œä¿ç•™æœ€è¿‘${maxVersions}ä¸ªç‰ˆæœ¬` };
  } catch (error) {
    throw new Error(`æ¸…ç†æ—§ç‰ˆæœ¬å¤±è´¥: ${error.message}`);
  }
}

app.listen(PORT, () => {
  console.log(`Backend server listening on http://localhost:${PORT}`);
  console.log('Projects dir:', DEFAULT_DIR);
  if (!fs.existsSync(CONFIG_PATH)) {
    console.log('Tip: create server/projects.json to define project paths explicitly.');
  }
});
